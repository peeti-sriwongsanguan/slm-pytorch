{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64f9a0d2-656c-4ca8-8fb2-fb7874944cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "# !pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9221c38-a607-4aa6-9c9f-0f247dce92fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0\n",
      "MPS available: True\n",
      "MPS built: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/peeti_mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peeti_mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS built: {torch.backends.mps.is_built()}\")\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm as std_tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89759fb9-f111-46a0-be34-921c5788d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CircuitNoteDataset class\n",
    "class CircuitNoteDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize and convert to indices\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        \n",
    "        # Pad or truncate to max_len\n",
    "        if len(token_ids) < self.max_len:\n",
    "            token_ids = token_ids + [0] * (self.max_len - len(token_ids))\n",
    "        else:\n",
    "            token_ids = token_ids[:self.max_len]\n",
    "            \n",
    "        return {\n",
    "            'input_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abebb44f-f87c-47ac-b496-68291d9d3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self, texts, max_vocab=10000):\n",
    "        # Create vocabulary from texts\n",
    "        try:\n",
    "            from nltk.corpus import stopwords\n",
    "            self.stop_words = set(stopwords.words('english'))\n",
    "        except (ImportError, LookupError):\n",
    "            # Fallback to a simple list of common stopwords\n",
    "            self.stop_words = self._get_basic_stopwords()\n",
    "            \n",
    "        all_words = []\n",
    "        \n",
    "        for text in texts:\n",
    "            words = self.preprocess_text(text)\n",
    "            all_words.extend(words)\n",
    "            \n",
    "        # Count word frequencies\n",
    "        from collections import Counter\n",
    "        word_counts = Counter(all_words)\n",
    "        \n",
    "        # Build vocabulary (most common words + special tokens)\n",
    "        vocab_words = [word for word, _ in word_counts.most_common(max_vocab-3)]\n",
    "        self.word2idx = {'<PAD>': 0, '<UNK>': 1, '<CLS>': 2}\n",
    "        for i, word in enumerate(vocab_words):\n",
    "            self.word2idx[word] = i + 3\n",
    "            \n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        # Make sure vocab_size is properly set\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "        print(f\"Vocabulary size: {self.vocab_size}\")\n",
    "        \n",
    "    def _get_basic_stopwords(self):\n",
    "        # Basic list of English stopwords\n",
    "        return set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', \n",
    "                   'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', \n",
    "                   'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', \n",
    "                   'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "                   'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', \n",
    "                   'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', \n",
    "                   'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', \n",
    "                   'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', \n",
    "                   'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', \n",
    "                   'into', 'through', 'during', 'before', 'after', 'above', 'below', \n",
    "                   'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', \n",
    "                   'under', 'again', 'further', 'then', 'once', 'here', 'there', \n",
    "                   'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "                   'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', \n",
    "                   'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', \n",
    "                   't', 'can', 'will', 'just', 'don', 'should', 'now'])\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        # Clean and tokenize text without using NLTK's word_tokenize\n",
    "        text = text.lower()\n",
    "        import re\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "        \n",
    "        # Simple space-based tokenization\n",
    "        words = text.split()\n",
    "        \n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word not in self.stop_words]\n",
    "        return words\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        words = self.preprocess_text(text)\n",
    "        return ['<CLS>'] + words\n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self.word2idx.get(token, self.word2idx['<UNK>']) for token in tokens]\n",
    "    \n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        return [self.idx2word.get(id, '<UNK>') for id in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf111b3-7142-495f-9394-c7509086f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout if n_layers > 1 else 0,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        # input_ids shape: [batch_size, seq_len]\n",
    "        embedded = self.dropout(self.embedding(input_ids))\n",
    "        # embedded shape: [batch_size, seq_len, embedding_dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        # If bidirectional, concat the final forward and backward hidden states\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "            \n",
    "        # hidden shape: [batch_size, hidden_dim]\n",
    "        \n",
    "        return self.fc(self.dropout(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02e864f-7796-440b-a9b9-5842370c1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_heads, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        # input_ids shape: [batch_size, seq_len]\n",
    "        \n",
    "        # Create mask for padding tokens\n",
    "        mask = (input_ids == 0)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input_ids))\n",
    "        # embedded shape: [batch_size, seq_len, embedding_dim]\n",
    "        \n",
    "        output = self.transformer_encoder(embedded, src_key_padding_mask=mask)\n",
    "        # Use the [CLS] token (first token) representation for classification\n",
    "        cls_output = output[:, 0, :]\n",
    "        \n",
    "        return self.fc(self.dropout(cls_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b94b4e9-3aca-4a48-8d94-a5c09e3edf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add visualization of training progress\n",
    "def plot_training_history(train_losses, valid_losses, train_accs, valid_accs):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    ax1.plot(train_losses, label='Train Loss')\n",
    "    ax1.plot(valid_losses, label='Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot accuracies\n",
    "    ax2.plot(train_accs, label='Train Accuracy')\n",
    "    ax2.plot(valid_accs, label='Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d96ee4-91e4-433e-ab86-7ebb93e7346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, device, epochs=10, accumulation_steps=4):\n",
    "    \"\"\"Train the model and evaluate on validation set with gradient accumulation\"\"\"\n",
    "    best_valid_loss = float('inf')\n",
    "    # To store training history\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 3\n",
    "    early_stop_counter = 0\n",
    "    \n",
    "    # Use regular tqdm instead of notebook tqdm\n",
    "    from tqdm import tqdm as std_tqdm\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_acc = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for i, batch in enumerate(std_tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} - Training')):\n",
    "                try:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    labels = batch['label'].to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    predictions = model(input_ids)\n",
    "                    \n",
    "                    # Calculate loss and scale it\n",
    "                    loss = criterion(predictions, labels) / accumulation_steps\n",
    "                    train_loss += loss.item() * accumulation_steps\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    preds = predictions.argmax(dim=1)\n",
    "                    train_acc += (preds == labels).sum().item() / len(labels)\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # Only update weights after accumulation_steps or at the end of the loader\n",
    "                    if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
    "                        # Gradient clipping to prevent exploding gradients\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                        \n",
    "                        # Update parameters\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        # Reset gradients\n",
    "                        optimizer.zero_grad()\n",
    "                    \n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Free up memory\n",
    "                    del input_ids, labels, predictions, loss, preds\n",
    "                    if hasattr(torch, 'cuda') and torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in batch {i}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Calculate average loss and accuracy\n",
    "            if batch_count > 0:  # Protect against division by zero\n",
    "                train_loss /= batch_count\n",
    "                train_acc /= batch_count\n",
    "            else:\n",
    "                print(\"Warning: No batches were successfully processed in this epoch\")\n",
    "                continue\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            valid_loss = 0\n",
    "            valid_acc = 0\n",
    "            valid_batch_count = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in std_tqdm(valid_loader, desc=f'Epoch {epoch+1}/{epochs} - Validation'):\n",
    "                    try:\n",
    "                        input_ids = batch['input_ids'].to(device)\n",
    "                        labels = batch['label'].to(device)\n",
    "                        \n",
    "                        # Forward pass\n",
    "                        predictions = model(input_ids)\n",
    "                        \n",
    "                        # Calculate loss\n",
    "                        loss = criterion(predictions, labels)\n",
    "                        valid_loss += loss.item()\n",
    "                        \n",
    "                        # Calculate accuracy\n",
    "                        preds = predictions.argmax(dim=1)\n",
    "                        valid_acc += (preds == labels).sum().item() / len(labels)\n",
    "                        \n",
    "                        valid_batch_count += 1\n",
    "                        \n",
    "                        # Free up memory\n",
    "                        del input_ids, labels, predictions, loss, preds\n",
    "                        if hasattr(torch, 'cuda') and torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in validation batch: {str(e)}\")\n",
    "                        continue\n",
    "            \n",
    "            # Calculate average validation loss and accuracy\n",
    "            if valid_batch_count > 0:\n",
    "                valid_loss /= valid_batch_count\n",
    "                valid_acc /= valid_batch_count\n",
    "            else:\n",
    "                print(\"Warning: No validation batches were successfully processed\")\n",
    "                continue\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{epochs}:')\n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "            print(f'Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}')\n",
    "            \n",
    "            # Save best model\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(model.state_dict(), 'best_circuit_note_model.pt')\n",
    "                print(\"Saved best model!\")\n",
    "                early_stop_counter = 0  # Reset counter when we have improvement\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "                print(f\"No improvement for {early_stop_counter} epochs\")\n",
    "            \n",
    "            # Store metrics\n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            valid_accs.append(valid_acc)\n",
    "            \n",
    "            # Save checkpoint at intervals\n",
    "            if (epoch + 1) % 2 == 0:  # Every 2 epochs\n",
    "                checkpoint_path = f'checkpoint_epoch_{epoch+1}.pt'\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss,\n",
    "                    'train_acc': train_acc,\n",
    "                    'valid_acc': valid_acc,\n",
    "                    'best_valid_loss': best_valid_loss,\n",
    "                }, checkpoint_path)\n",
    "                print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs due to no improvement in validation loss\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Training completed after {epoch+1} epochs\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Return training history\n",
    "    return train_losses, valid_losses, train_accs, valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1587ea49-d2ae-4b0f-85da-31d11ce5c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_circuit_status(model, tokenizer, text, device, label_encoder):\n",
    "    \"\"\"Make prediction on new circuit note text\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    # Pad or truncate to max_len (assuming max_len is 128)\n",
    "    max_len = 128\n",
    "    if len(token_ids) < max_len:\n",
    "        token_ids = token_ids + [0] * (max_len - len(token_ids))\n",
    "    else:\n",
    "        token_ids = token_ids[:max_len]\n",
    "    \n",
    "    # Convert to tensor\n",
    "    input_ids = torch.tensor([token_ids], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "        prediction = output.argmax(dim=1).item()\n",
    "    \n",
    "    # Convert back to label\n",
    "    predicted_label = label_encoder.inverse_transform([prediction])[0]\n",
    "    \n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b669af16-0fa1-4ac6-a4b4-7f251e148c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating synthetic data for demonstration...\n",
      "Train size: 350, Valid size: 75, Test size: 75\n",
      "Creating tokenizer...\n",
      "Vocabulary size: 52\n",
      "Using device: cpu (forced for stability)\n",
      "Initializing Transformer model...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Training: 100%|████████████████████| 88/88 [00:00<00:00, 519.97it/s]\n",
      "Epoch 1/5 - Validation: 100%|█████████████████| 19/19 [00:00<00:00, 2052.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "Train Loss: 1.4310, Train Acc: 0.4062\n",
      "Valid Loss: 0.7439, Valid Acc: 1.0000\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Training: 100%|████████████████████| 88/88 [00:00<00:00, 504.01it/s]\n",
      "Epoch 2/5 - Validation: 100%|█████████████████| 19/19 [00:00<00:00, 1734.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:\n",
      "Train Loss: 0.4172, Train Acc: 0.9318\n",
      "Valid Loss: 0.0189, Valid Acc: 1.0000\n",
      "Saved best model!\n",
      "Saved checkpoint at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Training: 100%|████████████████████| 88/88 [00:00<00:00, 544.56it/s]\n",
      "Epoch 3/5 - Validation: 100%|█████████████████| 19/19 [00:00<00:00, 1934.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:\n",
      "Train Loss: 0.0507, Train Acc: 0.9943\n",
      "Valid Loss: 0.0068, Valid Acc: 1.0000\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Training: 100%|████████████████████| 88/88 [00:00<00:00, 549.69it/s]\n",
      "Epoch 4/5 - Validation: 100%|█████████████████| 19/19 [00:00<00:00, 2114.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:\n",
      "Train Loss: 0.0221, Train Acc: 1.0000\n",
      "Valid Loss: 0.0041, Valid Acc: 1.0000\n",
      "Saved best model!\n",
      "Saved checkpoint at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Training: 100%|████████████████████| 88/88 [00:00<00:00, 563.86it/s]\n",
      "Epoch 5/5 - Validation: 100%|█████████████████| 19/19 [00:00<00:00, 2164.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:\n",
      "Train Loss: 0.0140, Train Acc: 1.0000\n",
      "Valid Loss: 0.0030, Valid Acc: 1.0000\n",
      "Saved best model!\n",
      "Training completed after 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████| 19/19 [00:00<00:00, 2312.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n",
      "\n",
      "Creating confusion matrix and classification report...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      active       1.00      1.00      1.00        15\n",
      "disconnected       1.00      1.00      1.00        15\n",
      "       error       1.00      1.00      1.00        15\n",
      " maintenance       1.00      1.00      1.00        15\n",
      "    migrated       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        75\n",
      "   macro avg       1.00      1.00      1.00        75\n",
      "weighted avg       1.00      1.00      1.00        75\n",
      "\n",
      "Script execution completed!\n",
      "\n",
      "Making predictions on sample notes:\n",
      "Note: 'Circuit disconnected per customer request'\n",
      "Predicted status: disconnected\n",
      "\n",
      "Note: 'Migration completed successfully with no issues'\n",
      "Predicted status: migrated\n",
      "\n",
      "Note: 'Error detected during testing phase'\n",
      "Predicted status: error\n",
      "\n",
      "Note: 'Active and stable with no packet loss'\n",
      "Predicted status: active\n",
      "\n",
      "Note: 'Maintenance scheduled for next Tuesday'\n",
      "Predicted status: maintenance\n",
      "\n",
      "Script execution completed!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Assume we have a DataFrame with columns 'note_text' and 'status'\n",
    "    # where status can be 'disconnected', 'migrated', 'error', etc.\n",
    "    \n",
    "    # Example code to load data (replace with actual data loading)\n",
    "    # df = pd.read_csv('circuit_notes.csv')\n",
    "    \n",
    "    # For demonstration, let's create some synthetic data\n",
    "    print(\"Creating synthetic data for demonstration...\")\n",
    "    \n",
    "    circuit_statuses = ['disconnected', 'migrated', 'error', 'active', 'maintenance']\n",
    "    \n",
    "    # Create synthetic data - in practice, replace this with your real data\n",
    "    notes = [\n",
    "        \"Circuit was disconnected due to customer request on 5/10\",\n",
    "        \"Successfully migrated from old platform to new one\",\n",
    "        \"Error reported: packet loss exceeding 5% during peak hours\",\n",
    "        \"Circuit active and functioning within normal parameters\",\n",
    "        \"Scheduled maintenance completed. All tests passed.\",\n",
    "        \"Customer requested disconnection due to relocation\",\n",
    "        \"Migration of services completed with no downtime\",\n",
    "        \"Error code 404 received when testing connection\",\n",
    "        \"Active monitoring shows stable connection\",\n",
    "        \"Maintenance window extended due to firmware update issues\"\n",
    "    ] * 50  # Replicate to get a larger dataset\n",
    "    \n",
    "    statuses = []\n",
    "    for note in notes:\n",
    "        if 'disconnect' in note.lower():\n",
    "            statuses.append('disconnected')\n",
    "        elif 'migrat' in note.lower():\n",
    "            statuses.append('migrated')\n",
    "        elif 'error' in note.lower():\n",
    "            statuses.append('error')\n",
    "        elif 'active' in note.lower():\n",
    "            statuses.append('active')\n",
    "        elif 'maintenance' in note.lower():\n",
    "            statuses.append('maintenance')\n",
    "        else:\n",
    "            # Just in case we missed something\n",
    "            statuses.append(np.random.choice(circuit_statuses))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'note_text': notes,\n",
    "        'status': statuses\n",
    "    })\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['status_encoded'] = label_encoder.fit_transform(df['status'])\n",
    "    \n",
    "    # Split data\n",
    "    train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "        df['note_text'].values, \n",
    "        df['status_encoded'].values,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=df['status_encoded']\n",
    "    )\n",
    "    \n",
    "    valid_texts, test_texts, valid_labels, test_labels = train_test_split(\n",
    "        temp_texts,\n",
    "        temp_labels,\n",
    "        test_size=0.5,\n",
    "        random_state=42,\n",
    "        stratify=temp_labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Train size: {len(train_texts)}, Valid size: {len(valid_texts)}, Test size: {len(test_texts)}\")\n",
    "    \n",
    "    # Create tokenizer\n",
    "    print(\"Creating tokenizer...\")\n",
    "    tokenizer = SimpleTokenizer(train_texts, max_vocab=5000)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    \n",
    "    MAX_LEN = 32\n",
    "    BATCH_SIZE = 4\n",
    "    EMBEDDING_DIM = 64\n",
    "\n",
    "\n",
    "    HIDDEN_DIM = 128\n",
    "    OUTPUT_DIM = len(label_encoder.classes_)\n",
    "    N_LAYERS = 1\n",
    "    BIDIRECTIONAL = True\n",
    "    N_HEADS = 8  # For transformer\n",
    "    DROPOUT = 0.2\n",
    "    EPOCHS = 5\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = CircuitNoteDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "    valid_dataset = CircuitNoteDataset(valid_texts, valid_labels, tokenizer, MAX_LEN)\n",
    "    test_dataset = CircuitNoteDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # # Set device - optimized for Apple Silicon\n",
    "    # if torch.backends.mps.is_available():\n",
    "    #     device = torch.device(\"mps\")\n",
    "    # elif torch.cuda.is_available():\n",
    "    #     device = torch.device(\"cuda\")\n",
    "    # else:\n",
    "    #     device = torch.device(\"cpu\")\n",
    "    # print(f\"Using device: {device}\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device} (forced for stability)\")\n",
    "    \n",
    "    # Choose model type based on preference (LSTM or Transformer)\n",
    "    model_type = \"transformer\"  # Change to \"lstm\" if you prefer LSTM\n",
    "    \n",
    "    if model_type == \"lstm\":\n",
    "        print(\"Initializing LSTM model...\")\n",
    "        model = LSTMClassifier(\n",
    "            vocab_size=tokenizer.vocab_size,\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            n_layers=N_LAYERS,\n",
    "            bidirectional=BIDIRECTIONAL,\n",
    "            dropout=DROPOUT\n",
    "        )\n",
    "    else:\n",
    "        print(\"Initializing Transformer model...\")\n",
    "        model = TransformerClassifier(\n",
    "            vocab_size=tokenizer.vocab_size,\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM * 4,  # Transformer typically uses larger feedforward layer\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            n_heads=N_HEADS,\n",
    "            n_layers=N_LAYERS,\n",
    "            dropout=DROPOUT\n",
    "        )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Train model\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    train_losses, valid_losses, train_accs, valid_accs = train_model(\n",
    "        model, train_loader, valid_loader, criterion, optimizer, device, \n",
    "        epochs=EPOCHS, accumulation_steps=4\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_circuit_note_model.pt'))\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_preds = []\n",
    "    test_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in std_tqdm(test_loader, desc='Testing'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(input_ids)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            preds = predictions.argmax(dim=1)\n",
    "            test_acc += (preds == labels).sum().item() / len(labels)\n",
    "            \n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "            test_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_acc /= len(test_loader)\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "    # Visualize confusion matrix\n",
    "    def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig('confusion_matrix.png')  # Save the figure\n",
    "        plt.show()\n",
    "        \n",
    "        # Print classification report\n",
    "        print(classification_report(y_true, y_pred, target_names=classes))\n",
    "    \n",
    "    # Create confusion matrix and classification report\n",
    "    print(\"\\nCreating confusion matrix and classification report...\")\n",
    "    plot_confusion_matrix(\n",
    "        [label_encoder.inverse_transform([label])[0] for label in test_true],\n",
    "        [label_encoder.inverse_transform([pred])[0] for pred in test_preds],\n",
    "        label_encoder.classes_\n",
    "    )\n",
    "    \n",
    "    print(\"Script execution completed!\")\n",
    "    \n",
    "    # Example of making predictions with the trained model\n",
    "    sample_notes = [\n",
    "        \"Circuit disconnected per customer request\",\n",
    "        \"Migration completed successfully with no issues\",\n",
    "        \"Error detected during testing phase\",\n",
    "        \"Active and stable with no packet loss\",\n",
    "        \"Maintenance scheduled for next Tuesday\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nMaking predictions on sample notes:\")\n",
    "    for note in sample_notes:\n",
    "        predicted_status = predict_circuit_status(model, tokenizer, note, device, label_encoder)\n",
    "        print(f\"Note: '{note}'\")\n",
    "        print(f\"Predicted status: {predicted_status}\\n\")\n",
    "    \n",
    "    print(\"Script execution completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56fad4-8faf-41a8-a31d-50753bd599c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
